# 二. Pipelining

[TOC]



<div align = center> <img src="https://zn-typora-image.oss-cn-hangzhou.aliyuncs.com/typora_image/202409121110299.png" width=100%> </div>

What is pipelining?  

How is the pipelining Implemented?  

What makes pipelining hard to implement?  

## 2.1 What is pipelining?

从两个角度进行加速：**`对每一条的指令进行加速；对一段程序的执行进行加速`**

Pipelining is an implementation technique whereby multiple instructions are overlapped in execution; it takes advantage of parallelism that exists among the actions needed to execute an instruction.

1. 对每一条指令的加速

   每条指令的执行可以被分解为多个阶段（在图中表现为三段），例如取指令、解码指令、执行指令等。这些阶段各自占用处理器的不同资源或部件。

   Pipelining 将这些阶段串联成“流水线”，而不是在执行完一条指令的所有阶段后才开始下一条指令。这样，不同的指令可以并行在流水线的不同阶段上执行。

   ![img](https://zn-typora-image.oss-cn-hangzhou.aliyuncs.com/typora_image/202409261104768.png)

   > **Buffer（缓冲区）**：为了使每个阶段能够顺畅工作，流水线中需要使用缓冲区暂存各阶段的中间结果，类似于传递信息的接力棒。

2. 对一段程序的加速

   > 执行模式的对比

   - **Sequential execution（顺序执行）**：

     在顺序执行中，处理器一次只执行一条指令，必须等到一条指令完全执行结束后，才能开始下一条指令。这是最慢的模式。

     假设每个阶段都需要1个时间单位，那么执行3条指令就需要9个时间单位（每条指令3个阶段，顺序执行）。

   - **Single overlapping execution（单次重叠执行）**：

     

   - **Twice overlapping execution（双次重叠执行）**：

     在双次重叠执行中，当一条指令完成了第一个阶段时，处理器会立即开始下一条指令的第一个阶段，而第一条指令进入第二阶段。这样指令之间有部分重叠。

     此模式加速了执行，使得3条指令只需要5个时间单位。

     

   

### 2.1.1 Sequential execution

没有流水线的时候，每一条指令顺序执行，执行时间就是每一条指令的每个阶段时间求和。

![img](https://zn-typora-image.oss-cn-hangzhou.aliyuncs.com/typora_image/202409121116444.png)



### 2.1.2 Overlapping execution

在重叠执行中，指令的各个阶段可以并行执行。例如，当第一条指令进入执行阶段（EX）时，第二条指令已经可以解码（ID），第三条指令开始取指（IF）。这样可以大幅提高吞吐量。然而，由于各个阶段的执行时间不同，可能会导致以下问题：

**等待与资源浪费**：

- 如果不同阶段的执行时间不一致，例如 ID 阶段的时间较长，那么其他阶段的执行单元会等待，资源就会被浪费。
- 如果 EX 阶段时间较长，则可能出现执行单元不够用的情况，导致流水线堵塞。

**理想情况：阶段时间均衡**

理想情况下，流水线的每个阶段（IF、ID、EX）的执行时间应该**相等**，这样可以保证流水线中的所有指令在每个阶段的处理都能顺利进行，避免资源浪费或冲突。

<div align = center> <img src="https://cdn.hobbitqia.cc/20230928231336.png" width=60%> </div>
<div align = center> <img src="https://cdn.hobbitqia.cc/20230928231419.png" width=60%> </div>



> **`Single Overlapping（单次重叠）`**

- 相较于顺序执行，单次重叠可以使指令并行工作，缩短了整体程序的执行时间。通常，可以减少 1/3 的执行时间（即处理器可以在一个周期内执行多条指令的不同阶段）。

- **挑战**：为实现这个效果，需要增加硬件开销（比如增加多个功能单元），并且引入了更多的“冒险”（Hazards），即由于指令之间的依赖关系可能产生的冲突。 

![img](https://zn-typora-image.oss-cn-hangzhou.aliyuncs.com/typora_image/202409121117798.png)

>   **`Twice Overlapping（双次重叠）`**

- 在双次重叠中，硬件进一步并行化，允许两个流水线阶段重叠得更加紧密，使得指令可以在更短的时间内完成。因此，理论上时间可以缩短 2/3。

- **硬件复杂性**：需要更复杂的硬件设计。例如，单独的取指单元、解码单元和执行单元都要独立工作，增加了硬件资源的消耗。

![img](https://zn-typora-image.oss-cn-hangzhou.aliyuncs.com/typora_image/202409121117446.png)

### 2.1.3 如何实现重叠？- buffer

1. buffer的引入

   - 存放阶段间的中间结果，避免由于下一个阶段的执行时间较长而导致前一个阶段需要等待。
   - 当 IF 阶段完成取指后，立即将指令放入 buffer 中，而不需要等待 ID 阶段完全解码完成。这样 IF 阶段可以尽快开始下一条指令的取指，增加了流水线的并行度。

2. buffer优化流水线

   - **减少等待时间**：即使 EX 阶段耗时较长，ID 阶段也不需要等待 EX 阶段完全执行完毕，因为 ID 阶段可以将解码结果暂时存放在 buffer 中。

   - **提高吞吐量**：通过 buffer 来存储各个阶段的临时结果，允许流水线继续向前推进，减少了各阶段之间的执行时间差异对流水线效率的影响。

3. 缓冲区机制（FIFO）

   - Buffer 通常使用 **FIFO（First In First Out，先进先出）** 机制来确保数据按照正确的顺序传递到下一个阶段。FIFO 的硬件实现不仅包括存储单元，还需要一些控制逻辑来管理数据的读取和写入。

> **Adding instruction buffer between memory and instruction decode unit.**  
>
> **添加 buffer 之后，IF 阶段时间变得很短，此时可以和 ID 阶段合并（把二次重叠变为了一次重叠）。**

Common features: They work by FIFO, and are composed of a group of several storage units that can be accessed quickly and related control logic. 
<div align = center> <img src="https://cdn.hobbitqia.cc/20230928232451.png" width=80%> </div>
<div align = center> <img src="https://cdn.hobbitqia.cc/20230928232708.png" width=80%> </div>

**`可以看到，添加 buffer 之后，ID 阶段不用等待 EX 阶段技术才能进行下一条的译码，因为 ID 阶段的结果已经存放在 buffer 中了。`**

## 2.2 Classes of pipelining

Characteristics of pipelining

* Single function pipelining: only one fixed function pipelining.

  - **`单功能流水线`**是最基础的流水线类型，具有固定的功能。处理器的流水线设计**`仅针对单一类型的运算`**，比如一个加法流水线只能处理加法运算，执行过程中无法执行其他类型的运算。

  - 例如，假设一个处理器有一条专门执行整数加法的流水线，则所有指令都必须遵循这个固定流程，其他类型的运算（如乘法或浮点操作）则不能使用这条流水线。

* Multi function pipelining: each section of the pipelining can be connected differently for several different functions.  
  
  **`多功能流水线`**可以在不同时间处理不同的运算类型，**`它的不同段可以灵活组合`**，实现不同的功能。这种设计允许处理器更灵活地分配计算资源。
  
  > ??? Example
  >
  >   <div align = center> <img src="https://zn-typora-image.oss-cn-hangzhou.aliyuncs.com/typora_image/202409121117537.png" width=80%> </div>
  
    针对多功能流水线的划分:
  
    * Static pipelining  
      
        静态流水线：同一时刻，整个流水线只能执行一个功能。**例如，处理器在某个时刻只能执行浮点加法，等这个加法运算结束后，才能开始乘法运算。换句话说，流水线的功能在同一时刻是固定的。**
  
    * Dynamic pipelining  
      
        同一时刻，流水线可以并行执行多个功能。例如，当一条指令在执行加法时，另一条指令可以同时进行乘法运算，这样提高了流水线的并行性和吞吐量。
        
        >   <div align = center> <img src="https://zn-typora-image.oss-cn-hangzhou.aliyuncs.com/typora_image/202409121118337.png" width=80%> </div>
  
        可以不用等浮点加法第 n 条结束，就可以开始浮点乘法。

还可以从**`不同粒度`**分类：

* Component level pipelining (in component - operation pipelining)

  在处理器内部组件内进行的流水线操作。例如，在同一个算术逻辑单元（ALU）内部，可以通过流水线技术让不同操作的各个阶段并行进行。

* Processor level pipelining (inter component - instruction pipelining)

  跨多个处理器组件的流水线操作，通常是指指令级的流水线。不同的指令在不同组件中进行取指、解码、执行等操作。

* Inter processor pipelining (inter processor - macro pipelining)

  这是更大规模的流水线设计，涉及多处理器或多核系统。在这种架构中，不同的处理器（或核）分别处理不同部分的任务。

还可以分为**`线性/非线性`**：

* Linear pipelining

  指令依次在流水线的各个阶段中处理，每个阶段只进行一次运算，数据不会返回到之前的阶段。指令从一端流入，处理完毕后从另一端流出。

* Nonlinear pipelining  
  
  在非线性流水线中，某些功能部件可能会被多次使用，造成回路。
  
  <div align = center> <img src="https://zn-typora-image.oss-cn-hangzhou.aliyuncs.com/typora_image/202409121118919.png" width=80%> </div>

还可以分为**`顺序/乱序`**：

* Ordered pipelining

  所有指令必须在按照进入流水线的顺序执行和完成。

* Disordered pipelining  

  后续的指令可以在前面指令执行未完成时就开始执行。
  
  当流水线中的某条指令由于等待数据而停滞时，处理器可以执行后续的指令。

还可以分为**`标量/向量处理器`**：

* Scalar processor

  在标量处理器中，流水线每次只能处理单一的数据元素。它的指令处理数据都是标量，意味着每条指令处理一个数据值。

* Vector pipelining processor: The processor has vector data representation and vector instructions. It is the combination of vector data representation and pipelining technology.  

  这种处理器采用向量指令处理多个数据元素（即一个向量）而不是单个标量。向量流水线的设计结合了向量数据表示与流水线技术，每次执行一条指令时处理的数据量非常大。

![image-20240926112953417](https://zn-typora-image.oss-cn-hangzhou.aliyuncs.com/typora_image/202409261129452.png)

## 2.3 Performance evaluation of pipelining

### 2.3.1 Throughput

> **`吞吐率是指单位时间内系统能处理的指令数量。`**

流水线希望我们单位时间内处理的任务越多越好，即提高吞吐率。

**Throughput(TP)** $TP=\dfrac{n}{T_K}<TP_{max}$（实际上 TP 会有损耗）

**n**：指令数。**$T_K$**：流水线的总执行时间。

<div align = center> <img src="https://zn-typora-image.oss-cn-hangzhou.aliyuncs.com/typora_image/202409121118547.png" width=80%> </div>

$TP=\dfrac{n}{n+m-1}TP_{max}$ **n** **为指令数，m为流水线stage数。**

if $n>>m, TP\approx TP_{max}$



Suppose the time of segments are different in pipelining, then the longest segment in the pipelining is called the **bottleneck segment**.

在流水线中，不同阶段可能需要不同的执行时间。最慢的阶段称为瓶颈段，它决定了整个流水线的最大吞吐率。

!!! Example 

> * $M = 4$
> * Time of S1, S3, S4: $\delta t$
> * Time of S2: $3\delta t$ (Bottleneck)
>
> <div align = center> <img src="https://cdn.hobbitqia.cc/20231019200840.png" width=60%> </div>
> <div align = center> <img src="https://cdn.hobbitqia.cc/20231019200853.png" width=60%> </div>
>
> 可以看到 $TP_{max}$ 只和瓶颈段的时间有关



> **`Common methods to solve pipeline bottleneck 解决流水线瓶颈的常见方法`**

* Subdivision 

    **`将瓶颈阶段进一步划分为多个子阶段`**，以并行执行。这样可以减少每个子阶段的执行时间，从而提升吞吐率。

    <div align = center> <img src="https://zn-typora-image.oss-cn-hangzhou.aliyuncs.com/typora_image/202409121120521.png" width=100%> </div>

    

* Repetition

    增加瓶颈阶段的硬件部件数量，使得该阶段可以并行处理更多的操作，从而提升整体吞吐率。
    
    <div align = center> <img src="https://zn-typora-image.oss-cn-hangzhou.aliyuncs.com/typora_image/202409121120471.png" width=100%> </div>
    
    

### 2.3.2 Speedup

加速比是指通过流水线技术，程序执行速度**`相对于非流水线系统`**的提升程度。

<div align = center> <img src="https://zn-typora-image.oss-cn-hangzhou.aliyuncs.com/typora_image/202409261132251.png" width=80%> </div>

$S_p = \dfrac{n\times m \times \delta t_0}{m(m+n-1)\delta t_0} = \dfrac{n}{m+n-1}$

if $n>>m, S_p\approx m$

### 2.3.3 Efficiency

效率表示流水线中硬件资源的利用率。即**`实际使用硬件资源的时间占整个执行过程的比例`**。

<div align = center> <img src="https://cdn.hobbitqia.cc/20231019201829.png" width=60%> </div>

$\eta = \dfrac{n\times m \times \delta t_0}{m(m+n-1)\delta t_0} = \dfrac{n}{m+n-1}$

* 注意效率得到的结果应该是百分比，之前的吞吐量、加速比都是没有量纲的数。
* 当指令数远大于流水线阶段数时（$n >> m$），效率趋近于 100%： $\eta \approx 1$

![image-20240926115148933](https://zn-typora-image.oss-cn-hangzhou.aliyuncs.com/typora_image/202409261151969.png)

### 2.3.4 Pipeline Performance

> Example "Vector Calculation in Static Pipeline"
>
> 现在有两个向量 A 和 B，我们要计算 A 点乘 B，通过下面的动态双功能流水线运算。
>
> ![img](https://zn-typora-image.oss-cn-hangzhou.aliyuncs.com/typora_image/202409121121158.png)
>
> 注意到这里是 **静态** 流水线，同一时刻只能做一类事情，需要先完成一种操作再完成另一种。这里我们需要先做乘法，排空，再做加法。做加法时，第三个乘法的结果需要等前两个乘法的结果相加后，再计算。
>
> <div align = center> <img src="https://cdn.hobbitqia.cc/20231019202702.png" width=60%> </div>
>
> <div align = center> <img src="https://zn-typora-image.oss-cn-hangzhou.aliyuncs.com/typora_image/202409261157005.png" width=60%> </div>
>
> 1. **对于TP的计算**
>
>    使用指令的条数，除以指令从开始运行到结束运行的总时钟周期数。因此是7/15。
>
> 2. **对于SP的计算**
>
>    用小方格的总数目（即真正使用了多少次stage）除以15，即花费的总时钟周期数，因此是24/15
>
> 3. **对于h的计算**
>
>    流水线的利用效率表示，**流水线的stage平均被利用的比例。**因此，用小方格的总数目（即真正使用了多少次stage）除以5*15，即花费的总时钟周期数乘以流水线stage个数，因此是24/75。

> Example "Vector Calculation in Dynamic Pipeline"
>
> **`动态流水线`**，可以在前一个功能还没有做完的时候执行另一个功能，不需要排空。
>
> <div align = center> <img src="https://zn-typora-image.oss-cn-hangzhou.aliyuncs.com/typora_image/202409121121874.png" width=60%> </div>
>
> 这里当两个乘法的结果算出来之后，就可以执行对应的加法。
> <div align = center> <img src="https://cdn.hobbitqia.cc/20231019221950.png" width=60%> </div>

流水线的段数 m 不是越多越好。

Too many stages:

* Lots of complications
* Should take care of possible dependencies among in-flight instructions
* Control logic is huge

1. **复杂性增加**

   - **流水线调度复杂**：更多的流水线段意味着更多的指令在不同阶段同时进行，这需要更复杂的调度逻辑来保证指令之间的协调。比如说，在每个时钟周期中，控制逻辑必须确保每个流水线段能够正确地接收、处理和输出指令。

   - **控制逻辑负担**：随着流水线段数的增加，控制逻辑的复杂度也大幅上升。特别是处理控制冒险和数据冒险时，必须有专门的硬件来解决指令间的依赖性，如转发单元和旁路技术。

2. 更多段带来的性能瓶颈

   - 虽然增加流水线段数可以缩短每个段的执行时间，从而提高单个时钟周期的频率，但并非所有计算任务都可以平等地划分成更多的小段。
   - **吞吐量的提升有限**：根据吞吐量公式 $TP = \frac{n}{n+m-1}TP_{\text{max}}$，随着段数 m 的增加，吞吐量 TP 确实会提高，但只有在指令数 n 远大于段数 m 时，才接近最大吞吐量。如果任务很小或有依赖性，增加段数的收益将非常有限。

3. 硬件要求提高

   - **更多的寄存器和缓冲区**：为了保证流水线段之间的数据传输，每个段之间必须使用**寄存器**或**缓冲区**存储中间结果。增加段数意味着需要更多的硬件来支持这些寄存器。
   - **分支预测的复杂性**：在较长的流水线中，分支指令的执行会有更长的延迟，因此需要更复杂的分支预测机制来减少控制冒险的影响。

流水线的性能有关：动态（不需要排空，但需要硬件支持）还是静态，流水线段数，代码质量（冒险）

## 2.4 Hazards of Pipelining

Hazards

* Situations that prevent starting the next instruction in the next cycle.
* **Structure hazards**

    A required resource is busy.

* **Data hazard**

    Need to wait for previous instruction to complete its data read/write.
    
* **Control hazard**

    Deciding on control action depends on previous instruction.

### Structure Hazards

<div align = center> <img src="https://cdn.hobbitqia.cc/20231019223244.png" width=60%> </div>

例如，某些系统中，指令取指（Instruction Fetch）和数据访问（Data Access）可能共用一个存储器单元，导致访问冲突。

- **增加硬件**：通过增加额外的资源（如独立的指令存储器和数据存储器）来避免争用。

- **引入气泡（bubble）**：当资源被占用时，插入气泡，使流水线暂停，直到资源可用。气泡会降低性能，但是解决结构冒险的简单方法。

### Data Hazards

An instruction depends on completion of data access by a previous instruction.  

数据冒险指的是某条指令依赖于前一条指令的结果，如果前一条指令尚未完成，后续指令无法继续执行。可以加 bubble, 或者通过 forwarding 前递数据，但并不是所有的情况都可以解决。

* **`Read after write: RAW`**  

    ``` asm
    FADD.D F6，F0，F12 // 将结果写入 F6
    FSUB.D F8，F6，F14 // 需要读取 F6
    ```

    Forwarding 解决这种类型的冒险。
    <div align = center> <img src="https://cdn.hobbitqia.cc/20231019223711.png" width=80%> </div>

* **`Write after read: WAR`**

    后续指令先写入一个寄存器，而之前的指令尚未完成读取该寄存器的值。这种冒险一般出现在乱序执行中。

    ``` asm
    FDIV.D F2，F6，F4
    FADD.D F6，F0，F12
    ```

    Name Dependences（在乱序流水线中可能出现冒险）

* **`Write after write: WAW`**
  
    两条指令都写入相同的寄存器，但出现了写入顺序的错误。
    
    ``` asm
    FDIV.D F2，F0，F4
    FSUB.D F2，F6，F14
    ```
    
    Name Dependences
    
* **`Load-use Hazard`**

    但是并不是所有的 RAW 都可以通过 Forwarding 解决，如 Load-use Hazard. 

    ```asm
    LD F6, 0(R1)
    ADD.D F2, F6, F4  // 需要等待前面的 load 完成
    ```
    
    - **插入气泡**：延迟后续指令的执行，直到前面的 load 指令完成。
    
    - > !!! Example "Code Scheduling to Avoid Stalls"
      >
      > **有的时候，我们可以对指令进行调度，改变指令的顺序，从而避免 stall 的情况。**
      >
      > <div align = center> <img src="https://zn-typora-image.oss-cn-hangzhou.aliyuncs.com/typora_image/202409261317304.png" width=80%> </div>
    
    - 静态调度：程序还没有运行，通过**`编译器在程序编译阶段重新排列指令顺序`**，减少等待时间。
    
    - 动态调度：处理器**`在执行时通过硬件优化指令顺序`**，减少停顿。

### Control Hazards

**定义**：控制冒险发生在流水线遇到分支指令时，必须等待分支指令的结果才能确定下一步的执行路径。如果分支预测错误，流水线必须丢弃错误路径上的指令。

为了减少分支指令带来的 stall，我们使用分支预测的技术。

* Static branch prediction
  
    基于分支的典型行为，编译器或硬件采用**固定的预测策略**。
    
    * Based on typical branch behavior
    * ***e.g.*** 循环，if-else 语句
        * Predict backward branches taken
        * Predict forward branches not taken
    
* Dynamic branch prediction
  
    硬件根据**历史数据**实时调整分支预测策略。动态预测通过**跟踪分支指令的历史行为**，在运行时预测下一次分支是否会被执行。
    
    * Hardware measures actual branch behavior
    * Assume future behavior will continue the trend
    
    **单比特预测器**：记录上一次分支的执行情况，简单预测是否重复相同的行为。
    
    **双比特预测器**：通过更复杂的**`状态机`**跟踪分支的历史行为，减少错误预测的概率。

## 2.5 Data Hazards: Forwarding vs. Stalling

## 2.6 Control Hazards

在流水线处理器中，控制冒险主要由**分支指令**（如无条件跳转和有条件跳转）引起。当处理器无法确定下一个要执行的指令时，可能会需要等待分支的决策结果，这会导致流水线停顿（stall）。为了减少控制冒险对流水线性能的影响，常用**分支预测**技术。

RISC-V 中的跳转指令包括：

- 无条件跳转：`jal, jalr`
- 有条件跳转：`beq, bne, blt, bge, bltu, bgeu`

RISC-V 通过在**指令解码阶段（ID 阶段）\**计算出跳转目标地址，同时进行\**分支预测**，仅在预测错误时才需要清空流水线（flush），以减少不必要的停顿。

### Static Branch Prediction

* Prediction taken 假设所有的分支都将会被执行（taken）。

    <div align = center> <img src="https://cdn.hobbitqia.cc/20231019224956.png" width=70%> </div>
    
* Prediction not taken 假设分支不会被执行（not taken）
* Delayed Branch

    The behavior of a delayed branched is the same whether or not the branch is taken.  
    
    即无论分支是否发生，分支后面的指令都要执行。（延时槽）

> !!! Question "Is delay slot a really good design?"
>
>  RISC-V 和微架构绑定不深，而且延迟槽也有弊端。
>
> **延迟槽**策略规定无论分支是否被执行，紧跟在分支指令后的指令都会被执行。由于延迟槽要求编译器重新排序指令，这种方法增加了程序的复杂性。RISC-V 并不强制支持延迟槽，因为它与硬件的微架构紧密绑定，且现代架构中延迟槽的有效性已经大大降低。

### Dynamic Branch Prediction

Use dynamic prediction

* Branch prediction buffer (aka branch history table)

* Indexed by recent branch instruction addresses

* Stores outcome (taken/not taken)

* To execute a branch
    * Check table, expect the same outcome

        把之前大家的结果存在一个表里，通过历史判断未来，根据之前的分支结果预测这次。
    
    * Start fetching from fall-through or target
    * If wrong, flush pipeline and flip prediction

> 分支预测缓冲区（Branch Prediction Buffer, BHT）BHT 是一个基于分支指令地址索引的表，**`存储了分支指令之前的执行结果（分支是否被执行）`**。当遇到分支指令时，处理器查询表中的记录来预测分支是否会被执行。如果预测错误，则清空流水线并更新预测结果。

#### Branch History Table(BHT)

<div align = center> <img src="https://cdn.hobbitqia.cc/20231019230118.png" width=80%> </div>

* 1-Bit Predictor

    - 单位预测器记录上次分支的结果，如果上次分支被执行，那么预测这次也会被执行；反之则预测不会被执行。
    - 缺点：容易在分支频繁变化时产生错误预测。

* 2-Bit Predictor
  
    <div align = center> <img src="https://cdn.hobbitqia.cc/20231019230256.png" width=100%> </div>

    - 双位预测器使用一个两位的有限状态机来跟踪分支的历史行为。在分支预测正确的情况下，需要连续两次错误才能改变预测结果。
    
    - 这种方式能够有效减少预测误差，并且性能开销较小，是最常用的动态分支预测方式。

#### Advanced Techniques for Instruction Delivery and Speculation

* Increasing Instruction Fetch Bandwidth
    * Branch-Target Buffers(BTBs) 分支目标缓冲区
        <div align = center> <img src="https://cdn.hobbitqia.cc/20231019230501.png" width=100%> </div>

        BTB 存储了分支指令和其目标地址。
        
        **如果在表中`找到了对应项`，那么立即取出对应项的目标地址，作为下一个时钟周期IF阶段PC，也就是说，如果表中有对应项，我们采取的预测方式是Assume Branch Taken。**
        
        - **分支预测正确**：处理器从 BTB 获取目标地址，**`并直接预取目标位置的指令`**。这大大提高了分支跳转的速度，减少了处理器在预测正确时的延迟。
        
        - **分支预测错误**：**`如果分支预测错误,则需要清空流水线并更新 BTB`，**将该PC对应的表项从目标地址缓存表中删除。
        
        **如果在表中没有找到对应项，我们采取的预测方式是Assume Branch Not Taken。**
        
        - 预测错误，清空已经执行的指令，并且下一个时钟周期使得目标地址进入IF阶段。与此同时，**`将这条分支指令的PC值以及对应的目标地址填入目标地址缓存表中，在表中新增一项。`**
        - **如果分支没有执行**正常情况，继续执行指令流即可。
        
        **`BTB 的更新与维护`**
        
        - **表加入机制**：当一个新的分支指令出现且其目标地址不在 BTB 中时，处理器会将这个分支指令和它的目标地址存入表中。
        - **表移除机制**：如果一个分支指令不再跳转（即不被执行），处理器会从 BTB 中移除该指令的条目，以腾出空间给其他分支指令。
        
        <div align = center> <img src="https://cdn.hobbitqia.cc/20231019230841.png" width=80%> </div>
    
* Specialized Branch Predictors: Predicting Procedure Returns, Indirect Jumps, and Loop Branches
  
    针对特定类型的分支指令，如函数返回、间接跳转和循环中的分支，现代处理器引入了**专门的分支预测器**来优化这些复杂场景中的预测行为。
    
    * **Predicting Procedure Returns（预测函数返回）**：由于函数返回指令通常会跳回到调用点，因此可以使用专门的预测机制来**`跟踪函数调用堆栈并准确预测返回地址`**。
    
      **Predicting Indirect Jumps（预测间接跳转）**：间接跳转指令（如函数指针跳转）难以直接预测，因为目标地址可能是动态计算的。通过维护间接跳转的历史记录，处理器可以**`根据之前的行为来预测未来的目标地址`**。
    
      **Predicting Loop Branches（预测循环分支）**：循环分支通常具有较高的可预测性，因为大多数循环会执行多次跳转，直到达到终止条件。专门的预测器可以利用这一特点来优化循环中的分支预测。
    
* branch folding
  
    **分支折叠**是一种技术，旨在消除分支指令带来的延迟。
    
    * It is possible to achieve unconditional branching without delay, or sometimes conditional branching without delay
    
* Benefit
    * **更快获取分支目标指令**：通过 BTB 和其他预测机制，处理器能够在分支跳转目标处快速获取指令，减少分支预测错误带来的流水线清空成本。
    
        **多指令预取**：BTB 允许处理器在分支目标处预取多个指令，确保分支预测正确时有足够的指令可供执行。这对于多处理器系统特别重要。
    
        
    
        

## 2.7 Schedule of Nonlinear pipelining

对于非线性流水线，功能部件可能经历多次，有调度问题。

> !!! Question
>
> 纵轴代表不同的功能部件，横坐标表示拍数。即每一拍需要用到的功能部件。
>
> <div align = center> <img src="https://zn-typora-image.oss-cn-hangzhou.aliyuncs.com/typora_image/202409121123029.png" width=60%> </div>
>
> **`上图表示，一条指令执行的过程一共需要7个时钟周期，每一个时钟周期分别使用哪些流水线部件。`**

![image-20240926134349326](https://zn-typora-image.oss-cn-hangzhou.aliyuncs.com/typora_image/202409261343364.png)

* Initial conflict vector

    二进制表示，第几拍是不能使用的。将几个二进制数取并集。

* Conflict vector
* State transition graph
* Circular queue
* Shortest average interval

> - Initial conflict vector
>
>   <div align = center> <img src="https://cdn.hobbitqia.cc/20231028103110.png" width=60%> </div>
>
>   对每一个部件分开来看
>
>   * 第一个部件，隔 8 拍会产生冲突；
>
>     第二个部件：可以看出隔5拍、隔6拍、隔1拍调度都是不行的；
>
>     第三个部件：没有限制；
>
>     第四、五个部件：1
>
>   * **`将对应二进制数的第 1、5、6、8 位设为 1，其他位为 0，得到了初始的冲突向量 10110001。该向量从低位到高位，用1来表示哪些调度间隔是不可行的。`**
>
>     <div align = center> <img src="https://zn-typora-image.oss-cn-hangzhou.aliyuncs.com/typora_image/202409261345210.png" width=60%> </div>
>
> - Conflict vector
>
>     1. **间隔2拍，进入第二条指令**
>
>        <div align = center> <img src="https://zn-typora-image.oss-cn-hangzhou.aliyuncs.com/typora_image/202409261349095.png" width=80%> </div>
>
>        指令1的C_init需要右移两位（这是因为此时已经隔了2拍），得到00101100。
>
>        同时，新进来的指令也有一个初始冲突向量，与C_init相同，为10110001。
>
>        此时，CCV(Current Conflict Vector)为两者做或操作的结果：10111101。
>
>     2. **再间隔2拍，进入第三条指令**
>
>        <div align = center> <img src="https://zn-typora-image.oss-cn-hangzhou.aliyuncs.com/typora_image/202409261350605.png" width=80%> </div>
>
>        指令1的冲突向量仍然需要右移两位，得到00001011。
>
>        指令2的冲突向量也需要右移两位，得到00101100。
>
>        指令3也有一个初始冲突向量，与C_init相同，为10110001。
>
>        此时，CCV(Current Conflict Vector)为三者做或操作的结果：10111111。
>
>     3. **此时只能再间隔7拍，进入第四条指令**
>
>        <div align = center> <img src="https://cdn.hobbitqia.cc/20231028104553.png" width=80%> </div>
>
>        与前面方法相同，得到CCV为四者做或操作的结果：10110001。
>
>        **`此时得到的现有冲突向量CCV和初始冲突向量C_init是完全相同的，都是10110001。`**
>
>        **`因此，上述过程可以构成一个闭环，我们可以使接连不断的指令按照2、2、7的间隔顺序进行调度。`**
>
> - State transition graph
>
>     <div align = center> <img src="https://cdn.hobbitqia.cc/20231028105340.png " width=100%> </div>
>
>     <center>
>         <img src="https://zn-typora-image.oss-cn-hangzhou.aliyuncs.com/typora_image/202410171035883.jpg" alt="微信图片_20241017103507" />
>     </center>
>
>     **`注意此处为circular queue，意思是形成环路即可，没有规定一定需要从初始状态回到初始状态`**
>     
>     
>     
>     在状态转移图中，从初始状态开始，路径上的数值表示相邻两条指令间隔的拍数。
>         
>     **`这样产生的调度，都是可行解。`**
>         
>     上图中存在很多环路，针对这些环路的调度方式我们可以算出**平均调度间隔**。**由此可知，3->4->3->4循环调度的平均调度间隔最小（3.5），因而是最优的。**